# Pyrallel Consumer

## ê³ ì„±ëŠ¥ Kafka ë³‘ë ¬ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬

`Pyrallel Consumer`ëŠ” Java ìƒíƒœê³„ì˜ `confluentinc/parallel-consumer`ì—ì„œ ì˜ê°ì„ ë°›ì•„, Python `asyncio` í™˜ê²½ì— ìµœì í™”ëœ ê³ ì„±ëŠ¥ Kafka ë³‘ë ¬ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. ë©”ì‹œì§€ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ë³‘ë ¬ ì²˜ë¦¬í•˜ë©´ì„œë„ ë°ì´í„° ì •í•©ì„±ê³¼ ìˆœì„œ ë³´ì¥ì„ ìµœìš°ì„ ìœ¼ë¡œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸŒŸ ì£¼ìš” íŠ¹ì§•

-   **ë³‘ë ¬ì„± ê·¹ëŒ€í™”**: Kafka íŒŒí‹°ì…˜ ìˆ˜ì— ì–½ë§¤ì´ì§€ ì•ŠëŠ” ìœ ì—°í•œ ë©”ì‹œì§€ ë³‘ë ¬ ì²˜ë¦¬.
-   **ì •êµí•œ ìˆœì„œ ë³´ì¥**: ë©”ì‹œì§€ í‚¤(Key) ê¸°ì¤€ìœ¼ë¡œ ì²˜ë¦¬ ìˆœì„œë¥¼ ìœ ì§€í•˜ì—¬ ë°ì´í„° ì¼ê´€ì„± ë³´ì¥.
-   **ë°ì´í„° ì •í•©ì„±**: ë¦¬ë°¸ëŸ°ì‹± ë° ì¬ì‹œì‘ ì‹œ ì¤‘ë³µ ì²˜ë¦¬ë¥¼ ìµœì†Œí™”í•˜ëŠ” 'êµ¬ë©(Gap) ê¸°ë°˜ ì˜¤í”„ì…‹ ì»¤ë°‹' êµ¬í˜„.
-   **ì•ˆì •ì„± ë° ê°€ì‹œì„±**: `Epoch-based Fencing`ì„ í†µí•œ ë¦¬ë°¸ëŸ°ì‹± ì•ˆì •ì„± í™•ë³´ ë° ìƒì„¸ ëª¨ë‹ˆí„°ë§ ì§€í‘œ ì œê³µ.
-   **ìœ ì—°í•œ ì‹¤í–‰ ëª¨ë¸**: `AsyncExecutionEngine`ê³¼ `ProcessExecutionEngine` ì¤‘ ëŸ°íƒ€ì„ì— ì„ íƒ ê°€ëŠ¥í•œ í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜ ì œê³µ.

## ğŸ“ˆ Observability

`KafkaConfig.metrics` ì„¹ì…˜ì„ í†µí•´ í”„ë¡œë©”í…Œìš°ìŠ¤ ì§€í‘œë¥¼ ë…¸ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ ë¹„í™œì„±í™”(`enabled=False`)ì´ë©°, ì•„ë˜ì™€ ê°™ì´ ì„¤ì •í•˜ë©´ `http://<host>:<port>/metrics`ì—ì„œ Scrape í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
from pyrallel_consumer.config import KafkaConfig

config = KafkaConfig()
config.metrics.enabled = True
config.metrics.port = 9095
consumer = PyrallelConsumer(config, worker, topic="demo")
```

### ë…¸ì¶œë˜ëŠ” í•µì‹¬ ì§€í‘œ

| Metric | Type | Labels | ì„¤ëª… |
| --- | --- | --- | --- |
| `consumer_processed_total` | Counter | `topic`, `partition`, `status` | ì™„ë£Œëœ ë©”ì‹œì§€ ìˆ˜ (ì„±ê³µ/ì‹¤íŒ¨ êµ¬ë¶„) |
| `consumer_processing_latency_seconds` | Histogram | `topic`, `partition` | WorkManager ì œì¶œ â†’ Completion ê¹Œì§€ì˜ ì§€ì—° |
| `consumer_in_flight_count` | Gauge | â€“ | í˜„ì¬ ì¸í”Œë¼ì´íŠ¸ ë©”ì‹œì§€ ìˆ˜ |
| `consumer_parallel_lag` | Gauge | `topic`, `partition` | True lag (`last_fetched - last_committed`) |
| `consumer_gap_count` | Gauge | `topic`, `partition` | ì»¤ë°‹ì„ ë§‰ê³  ìˆëŠ” Gap ìˆ˜ |
| `consumer_internal_queue_depth` | Gauge | `topic`, `partition` | ê°€ìƒ íŒŒí‹°ì…˜ íì— ëŒ€ê¸° ì¤‘ì¸ ë©”ì‹œì§€ |
| `consumer_oldest_task_duration_seconds` | Gauge | `topic`, `partition` | Blocking offsetì´ ë§‰ê³  ìˆëŠ” ì‹œê°„ |
| `consumer_backpressure_active` | Gauge | â€“ | Backpressure ë™ì‘ ì—¬ë¶€ (1=Pause) |
| `consumer_metadata_size_bytes` | Gauge | `topic` | Kafka ì»¤ë°‹ ë©”íƒ€ë°ì´í„° í˜ì´ë¡œë“œ í¬ê¸° |

ì´ ì§€í‘œë“¤ì€ `BrokerPoller.get_metrics()`ì™€ ë™ì¼í•œ ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±ë˜ë©°, Grafana ëŒ€ì‹œë³´ë“œ êµ¬ì„± ì‹œ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ìƒ˜í”Œ (í”„ë¡œíŒŒì¼ OFF)

ìµœê·¼ ì‹¤í–‰(4 partitions, 2000 msgs, 100 keys, profiling off)ì˜ ì²˜ë¦¬ëŸ‰(TPS)ì„ ì•„ë˜ì— ê³µìœ í•©ë‹ˆë‹¤. ì›Œí¬ë¡œë“œëŠ” `benchmarks/run_parallel_benchmark.py`ì˜ `--workload` ì˜µì…˜ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ì‹¤í–‰ ì‹œ í”„ë¡œíŒŒì¼ë§ì€ ëª¨ë‘ ë¹„í™œì„±í™”í–ˆìŠµë‹ˆë‹¤.

| Workload | ì„¤ì • | baseline TPS | async TPS | process TPS |
| --- | --- | --- | --- | --- |
| sleep | `--workload sleep --worker-sleep-ms 5` | 159.69 | 2206.35 | 910.04 |
| cpu | `--workload cpu --worker-cpu-iterations 500` | 2598.79 | 1403.07 | 2072.26 |
| io | `--workload io --worker-io-sleep-ms 5` | 159.89 | 2797.18 | 916.60 |

> ì£¼ì˜: í”„ë¡œì„¸ìŠ¤ ëª¨ë“œëŠ” ì•ˆì •ì„±ì„ ìœ„í•´ í”„ë¡œíŒŒì¼ì„ ë¹„í™œì„±í™”í•œ ìƒíƒœë¡œ ì‹¤í–‰í–ˆìŠµë‹ˆë‹¤. í”„ë¡œíŒŒì¼ì´ í•„ìš”í•˜ë©´ baseline/async ìœ„ì£¼ë¡œ ì‚¬ìš©í•˜ê±°ë‚˜ ë³„ë„ ì™¸ë¶€ í”„ë¡œíŒŒì¼ëŸ¬(py-spy ë“±)ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.

## ğŸš€ ì•„í‚¤í…ì²˜ ê°œìš”

`Pyrallel Consumer`ëŠ” **Control Plane**, **Execution Plane**, **Worker Layer**ë¡œ ëª…í™•í•˜ê²Œ ê³„ì¸µì„ ë¶„ë¦¬í•˜ì—¬ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. `Control Plane`ì€ Kafkaì™€ì˜ í†µì‹  ë° ì˜¤í”„ì…‹ ê´€ë¦¬ë¥¼ ë‹´ë‹¹í•˜ë©°, ì–´ë–¤ `Execution Engine`ì´ ì‚¬ìš©ë˜ëŠ”ì§€ì— ë…ë¦½ì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤. `Execution Plane`ì€ `Asyncio Task` ë˜ëŠ” `ë©€í‹°í”„ë¡œì„¸ìŠ¤`ë¥¼ í™œìš©í•˜ì—¬ ì‚¬ìš©ì ì •ì˜ ì›Œì»¤ì˜ ë³‘ë ¬ ì‹¤í–‰ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.

```mermaid
graph TD
    subgraph "Ingress Layer (Kafka Client)"
        A["Kafka Broker"] --> B["BrokerPoller"]
    end

    subgraph "Routing Layer (Dispatcher)"
        B --> C{"Key Extractor"}
        C --> D["Virtual Partition 1"]
        C --> E["Virtual Partition 2"]
    end

    subgraph "Execution Layer (Execution Engine)"
        D --> G["ExecutionEngine.submit"]
        E --> G
        G --> H["AsyncExecutionEngine"]
        G --> I["ProcessExecutionEngine"]
        H --> J["Async Worker Task"]
        I --> K["Process Worker"]
        J & K --> L["Completion Channel"]
    end

    subgraph "Management & Control (Control Plane)"
        L --> M["WorkManager"]
        M --> N["Offset Tracker"]
        N --> O["Commit Encoder"]
    end
```

## ğŸ› ï¸ ì„¤ì¹˜ ë° ì„¤ì •

### ì˜ì¡´ì„± ê´€ë¦¬: `uv`
í”„ë¡œì íŠ¸ì˜ ëª¨ë“  ì˜ì¡´ì„± ì„¤ì¹˜ ë° ê´€ë¦¬ëŠ” `uv` íˆ´ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
```bash
# uv ì„¤ì¹˜ (ì•„ì§ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ë‹¤ë©´)
pip install uv

# í”„ë¡œì íŠ¸ ì˜ì¡´ì„± ì„¤ì¹˜
uv pip install -r requirements.txt

# ê°œë°œ í™˜ê²½ ì˜ì¡´ì„± ì„¤ì¹˜ (ì„ íƒ ì‚¬í•­)
uv pip install -r dev-requirements.txt
```

### íŒ¨í‚¤ì§€ ì„¤ì¹˜/ë°°í¬ (ë¡œì»¬ ë¹Œë“œ)
```bash
# ë¡œì»¬ ì„¤ì¹˜ (editable ì•„ë‹˜)
pip install .

# sdist/wheel ë¹Œë“œ
python -m pip install build
python -m build

# ìƒì„±ë¬¼: dist/*.tar.gz, dist/*.whl
# ì˜ˆì‹œ ì—…ë¡œë“œ (twine ì‚¬ìš© ì‹œ)
# python -m pip install twine
# twine upload dist/*
```

### ë³´ì•ˆ/ì„¤ì • ë©”ëª¨
- Grafana(admin): `docker-compose.yml`ëŠ” `GF_SECURITY_ADMIN_PASSWORD`ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê¸°ëŒ€í•©ë‹ˆë‹¤. ì‹¤í–‰ ì „ `.env`ì— ê°’ì„ ë„£ìœ¼ì„¸ìš”.
- DLQ: `KAFKA_DLQ_PAYLOAD_MODE`ë¥¼ `metadata_only`ë¡œ ì„¤ì •í•˜ë©´ í‚¤/ê°’ ëŒ€ì‹  í—¤ë” ë©”íƒ€ë°ì´í„°ë§Œ DLQì— ê²Œì‹œí•©ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ `full`(ê¸°ì¡´ ë™ì‘ ìœ ì§€).
- ë¼ì´ì„ ìŠ¤: Apache-2.0

### ì„¤ì •: `pydantic-settings`
í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” `.env` íŒŒì¼ì„ í†µí•´ Kafka í´ë¼ì´ì–¸íŠ¸ ë° ì»¨ìŠˆë¨¸ ì„¤ì •ì„ ê´€ë¦¬í•©ë‹ˆë‹¤. `KafkaConfig` í´ë˜ìŠ¤(pyrallel_consumer/config.py ì°¸ì¡°)ë¥¼ í†µí•´ ë¡œë“œë©ë‹ˆë‹¤.

ì˜ˆì‹œ `.env` íŒŒì¼:
```dotenv
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_CONSUMER_GROUP=my-consumer-group
EXECUTION_MODE=async # ë˜ëŠ” process
```

### ì¬ì‹œë„ ë° DLQ (Dead Letter Queue) ì„¤ì •

Pyrallel ConsumerëŠ” ì‹¤íŒ¨í•œ ë©”ì‹œì§€ì— ëŒ€í•œ ìë™ ì¬ì‹œë„ì™€ DLQ í¼ë¸”ë¦¬ì‹±ì„ ì§€ì›í•©ë‹ˆë‹¤.

#### ì¬ì‹œë„ ì„¤ì • (`ExecutionConfig`)

ì¬ì‹œë„ëŠ” ê° Execution Engine ë‚´ë¶€ì—ì„œ ë©”ì‹œì§€ë³„ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤:

| í™˜ê²½ ë³€ìˆ˜ | ê¸°ë³¸ê°’ | ì„¤ëª… |
| --- | --- | --- |
| `EXECUTION_MAX_RETRIES` | `3` | ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ (ì‹¤íŒ¨ ì‹œ ì´ ì‹œë„ íšŸìˆ˜ = max_retries) |
| `EXECUTION_RETRY_BACKOFF_MS` | `1000` | ì´ˆê¸° ë°±ì˜¤í”„ ì§€ì—° ì‹œê°„ (ë°€ë¦¬ì´ˆ) |
| `EXECUTION_EXPONENTIAL_BACKOFF` | `true` | ì§€ìˆ˜ ë°±ì˜¤í”„ ì‚¬ìš© ì—¬ë¶€ (`false`ë©´ ì„ í˜• ë°±ì˜¤í”„) |
| `EXECUTION_MAX_RETRY_BACKOFF_MS` | `30000` | ìµœëŒ€ ë°±ì˜¤í”„ ìƒí•œì„  (ë°€ë¦¬ì´ˆ) |
| `EXECUTION_RETRY_JITTER_MS` | `200` | ë°±ì˜¤í”„ì— ì¶”ê°€í•  ëœë¤ ì§€í„° ë²”ìœ„ (ë°€ë¦¬ì´ˆ) |

ë°±ì˜¤í”„ ê³„ì‚° ë°©ì‹:
- **ì§€ìˆ˜ ë°±ì˜¤í”„**: `min(retry_backoff_ms * 2^(attempt-1), max_retry_backoff_ms) + random(0, jitter_ms)`
- **ì„ í˜• ë°±ì˜¤í”„**: `min(retry_backoff_ms * attempt, max_retry_backoff_ms) + random(0, jitter_ms)`

#### DLQ ì„¤ì • (`KafkaConfig`)

ì¬ì‹œë„ë¥¼ ëª¨ë‘ ì†Œì§„í•œ ì‹¤íŒ¨ ë©”ì‹œì§€ëŠ” DLQ í† í”½ìœ¼ë¡œ í¼ë¸”ë¦¬ì‹±ë©ë‹ˆë‹¤:

| í™˜ê²½ ë³€ìˆ˜ | ê¸°ë³¸ê°’ | ì„¤ëª… |
| --- | --- | --- |
| `KAFKA_DLQ_ENABLED` | `true` | DLQ í¼ë¸”ë¦¬ì‹± í™œì„±í™” ì—¬ë¶€ |
| `KAFKA_DLQ_TOPIC_SUFFIX` | `.dlq` | ì›ë³¸ í† í”½ ì´ë¦„ì— ë¶™ì¼ DLQ í† í”½ ì ‘ë¯¸ì‚¬ |

DLQ í† í”½ìœ¼ë¡œ ì „ì†¡ë˜ëŠ” ë©”ì‹œì§€ëŠ” ë‹¤ìŒ í—¤ë”ë¥¼ í¬í•¨í•©ë‹ˆë‹¤:

| í—¤ë” í‚¤ | ì„¤ëª… | ì˜ˆì‹œ |
| --- | --- | --- |
| `x-error-reason` | ìµœì¢… ì‹¤íŒ¨ ì—ëŸ¬ ë©”ì‹œì§€ | `"ValueError: invalid data"` |
| `x-retry-attempt` | ìµœì¢… ì‹œë„ íšŸìˆ˜ | `"3"` |
| `source-topic` | ì›ë³¸ í† í”½ ì´ë¦„ | `"orders"` |
| `partition` | ì›ë³¸ íŒŒí‹°ì…˜ ë²ˆí˜¸ | `"2"` |
| `offset` | ì›ë³¸ ì˜¤í”„ì…‹ | `"12345"` |
| `epoch` | íŒŒí‹°ì…˜ í• ë‹¹ ì—í¬í¬ (ë¦¬ë°¸ëŸ°ì‹± ì¶”ì ìš©) | `"1"` |

**ë™ì‘ íë¦„:**
1. ì›Œì»¤ í•¨ìˆ˜ ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ Execution Engineì´ ì¬ì‹œë„
2. `max_retries` ë„ë‹¬ ì‹œ `CompletionEvent.status = FAILURE`, `attempt = max_retries`ë¡œ ë°˜í™˜
3. `BrokerPoller`ê°€ DLQ í¼ë¸”ë¦¬ì‹± ì‹¤í–‰ (í™œì„±í™”ëœ ê²½ìš°)
4. DLQ í¼ë¸”ë¦¬ì‹± ì„±ê³µ ì‹œì—ë§Œ ì˜¤í”„ì…‹ ì»¤ë°‹
5. DLQ í¼ë¸”ë¦¬ì‹± ì‹¤íŒ¨ ì‹œ ì˜¤í”„ì…‹ ì»¤ë°‹ ê±´ë„ˆë›°ê³  ì—ëŸ¬ ë¡œê¹…

**ì˜ˆì œ:**

## ğŸ’¡ ì‚¬ìš©ë²•

### ì¬ì‹œë„ & DLQ ì„¤ì • (ìš”ì•½)
- `KafkaConfig.dlq_enabled` (ê¸°ë³¸ `True`): ì‹¤íŒ¨ ë©”ì‹œì§€ë¥¼ DLQë¡œ ë°œí–‰í• ì§€ ì—¬ë¶€
- `KafkaConfig.DLQ_TOPIC_SUFFIX` (ê¸°ë³¸ `.dlq`): DLQ í† í”½ ì ‘ë¯¸ì‚¬ (`<ì›ë³¸í† í”½><ì ‘ë¯¸ì‚¬>`)
- `ExecutionConfig.max_retries` (ê¸°ë³¸ `3`): ì›Œì»¤ ì‹¤í–‰ ì¬ì‹œë„ íšŸìˆ˜
- `ExecutionConfig.retry_backoff_ms` (ê¸°ë³¸ `1000`): ì¬ì‹œë„ ëŒ€ê¸° ì‹œì‘ê°’(ms)
- `ExecutionConfig.exponential_backoff` (ê¸°ë³¸ `True`): ì§€ìˆ˜ ë°±ì˜¤í”„ ì‚¬ìš© ì—¬ë¶€
- `ExecutionConfig.max_retry_backoff_ms` (ê¸°ë³¸ `30000`), `retry_jitter_ms` (ê¸°ë³¸ `200`)
- ë™ì‘: ìµœëŒ€ ì¬ì‹œë„ í›„ ì‹¤íŒ¨ ì‹œ DLQë¡œ ë°œí–‰(`dlq_enabled=True`), DLQ ì ì¬ ì„±ê³µ ì‹œì—ë§Œ ì»¤ë°‹

ì˜ˆì‹œ `.env` (ë°œì·Œ)
```env
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_CONSUMER_GROUP=my-consumer-group
EXECUTION_MODE=async              # async | process
EXECUTION_MAX_IN_FLIGHT=512
KAFKA_DLQ_ENABLED=true
KAFKA_DLQ_TOPIC_SUFFIX=.failed
METRICS_ENABLED=true
METRICS_PORT=9091
```

```python
from pyrallel_consumer.consumer import PyrallelConsumer
from pyrallel_consumer.config import KafkaConfig, ExecutionConfig
from pyrallel_consumer.dto import ExecutionMode, WorkItem

config = KafkaConfig()
config.dlq_enabled = True
config.DLQ_TOPIC_SUFFIX = ".failed"

exec_conf = ExecutionConfig()
exec_conf.mode = ExecutionMode.ASYNC
exec_conf.max_retries = 5
exec_conf.retry_backoff_ms = 2000

async def worker(item: WorkItem):
    ...

consumer = PyrallelConsumer(config=config, worker=worker, topic="orders")
```

### ğŸ ë¹ ë¥¸ ì‹œì‘ (ì„ íƒ) â€” DLQ ì„¤ì • í¬í•¨ ì˜ˆì œ

1) ì„¤ì¹˜
```bash
pip install -r requirements.txt
```

2) ì„¤ì • + ì›Œì»¤ + ì‹¤í–‰
```python
import asyncio
import hashlib
import time

from pyrallel_consumer.consumer import PyrallelConsumer
from pyrallel_consumer.config import KafkaConfig, ExecutionConfig
from pyrallel_consumer.dto import ExecutionMode, WorkItem

config = KafkaConfig(
    BOOTSTRAP_SERVERS=["localhost:9092"],
    CONSUMER_GROUP="demo-group",
    AUTO_OFFSET_RESET="earliest",
)
config.dlq_enabled = True
config.DLQ_TOPIC_SUFFIX = ".failed"

exec_conf = ExecutionConfig()
exec_conf.mode = ExecutionMode.ASYNC  # ë˜ëŠ” ExecutionMode.PROCESS
exec_conf.max_in_flight = 512
exec_conf.max_retries = 5
exec_conf.retry_backoff_ms = 2000

async def io_worker(item: WorkItem):
    _ = (item.payload or b"").decode("utf-8")
    await asyncio.sleep(0.005)

def cpu_worker(item: WorkItem):
    data = item.payload or b""
    for _ in range(500):
        data = hashlib.sha256(data).digest()

def sleep_worker(item: WorkItem):
    _ = (item.payload or b"").decode("utf-8")
    time.sleep(0.005)

consumer = PyrallelConsumer(
    config=config,
    worker=io_worker,  # ë˜ëŠ” cpu_worker / sleep_worker
    topic="demo-topic",
)

async def main():
    await consumer.start()
    try:
        await asyncio.sleep(60)
    finally:
        await consumer.stop()

asyncio.run(main())
```

3) ì‹¤í–‰ ì—”ì§„ ì„ íƒ íŒ
- I/O ë°”ìš´ë“œ: `ExecutionMode.ASYNC`, async ì›Œì»¤ ì‚¬ìš©
- CPU ë°”ìš´ë“œ: `ExecutionMode.PROCESS`, picklable sync ì›Œì»¤ ì‚¬ìš©
- ë™ì‹œ ì²˜ë¦¬ëŸ‰: `max_in_flight`, `worker_pool_size`ë¥¼ í•¨ê»˜ ì¡°ì •

For detailed examples including async mode, process mode, configuration tuning, and graceful shutdown patterns, see the **[`examples/`](./examples/)** directory.

## ğŸ§ª ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰

`benchmarks/run_parallel_benchmark.py` ìŠ¤í¬ë¦½íŠ¸ëŠ” í”„ë¡œë“€ì„œ â†’ ë² ì´ìŠ¤ë¼ì¸ ì»¨ìŠˆë¨¸ â†’ Pyrallel (async/process) ìˆœì„œë¡œ ë²¤ì¹˜ë§ˆí¬ë¥¼ ìë™ ì‹¤í–‰í•©ë‹ˆë‹¤. Kafkaê°€ ë¡œì»¬ì—ì„œ ì‹¤í–‰ ì¤‘ì´ë¼ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
uv run python benchmarks/run_parallel_benchmark.py \
  --bootstrap-servers localhost:9092 \
  --num-messages 50000 \
  --num-keys 200 \
  --num-partitions 8
```

- ì½˜ì†”ì—ëŠ” ê° ëŸ¬ìš´ë“œë³„ TPS / í‰ê·  / P99 ì§€ì—°ì´ í‘œ í˜•íƒœë¡œ ì¶œë ¥ë©ë‹ˆë‹¤.
- JSON ë¦¬í¬íŠ¸ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ `benchmarks/results/<UTC íƒ€ì„ìŠ¤íƒ¬í”„>.json`ì— ì €ì¥ë©ë‹ˆë‹¤.
- `--skip-baseline`, `--skip-async`, `--skip-process` í”Œë˜ê·¸ë¥¼ í†µí•´ íŠ¹ì • ë¼ìš´ë“œë¥¼ ê±´ë„ˆë›¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ê¸°ë³¸ ë™ì‘ìœ¼ë¡œ AdminClientë¥¼ ì‚¬ìš©í•´ ë²¤ì¹˜ë§ˆí¬ í† í”½ê³¼ ì»¨ìŠˆë¨¸ ê·¸ë£¹ì„ ì‚­ì œ í›„ ì¬ìƒì„±í•˜ì—¬ ì´ì „ ì‹¤í–‰ì˜ ë ˆê·¸ê°€ ì„ì´ì§€ ì•ŠìŠµë‹ˆë‹¤. í´ëŸ¬ìŠ¤í„° ê¶Œí•œì´ ì—†ê±°ë‚˜ ìˆ˜ë™ ì œì–´ê°€ í•„ìš”í•œ ê²½ìš° `--skip-reset` í”Œë˜ê·¸ë¡œ ì¬ì„¤ì •ì„ ë¹„í™œì„±í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ì›Œì»¤ê°€ ëŠë ¤ì§ˆ ë•ŒëŠ” `--timeout-sec` ê°’(ê¸°ë³¸ 60ì´ˆ)ì„ ëŠ˜ë ¤ async/process ë¼ìš´ë“œì˜ íƒ€ì„ì•„ì›ƒì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ“– ë¬¸ì„œ

-   **`prd_dev.md`**: ê°œë°œìë¥¼ ìœ„í•œ ìš”ì•½ ë¬¸ì„œ. í”„ë¡œì íŠ¸ì˜ ì£¼ìš” ê¸°ëŠ¥, ì•„í‚¤í…ì²˜, ê°œë°œ ë°©ë²•ë¡  ë“±ì„ ê°„ê²°í•˜ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤.
-   **`prd.md`**: ìƒì„¸ ì„¤ê³„ í•´ì„¤ì„œ. ê° ì»´í¬ë„ŒíŠ¸ì˜ ì˜ë„, ê¸°ìˆ  ì„ ì • ì´ìœ , ì¸í„°í˜ì´ìŠ¤ ì •ì˜ ë“± "ì™œ"ë¼ëŠ” ì§ˆë¬¸ì— ëŒ€í•œ ê¹Šì´ ìˆëŠ” ë‹µë³€ì„ ì œê³µí•˜ëŠ” ë¬¸ì„œì…ë‹ˆë‹¤.

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ (Prometheus + Grafana)

- `docker-compose.yml`ì— Prometheus(9090), Grafana(3000), Kafka Exporter(9308), Kafka UI(8080), Kafka(9092)ê°€ í¬í•¨ë©ë‹ˆë‹¤.
- Prometheus ì„¤ì •ì€ `monitoring/prometheus.yml`ì—ì„œ ê´€ë¦¬í•˜ë©° ê¸°ë³¸ìœ¼ë¡œ `kafka-exporter`ì™€ í˜¸ìŠ¤íŠ¸ì˜ Pyrallel Consumer(ë©”íŠ¸ë¦­ í¬íŠ¸ 9091)ë¥¼ ìŠ¤í¬ë©í•©ë‹ˆë‹¤. ì»¨ìŠˆë¨¸ê°€ ì»¨í…Œì´ë„ˆ ë‚´ì—ì„œ ëŒë©´ í•´ë‹¹ ì£¼ì†Œë¥¼ ì»¨í…Œì´ë„ˆ í˜¸ìŠ¤íŠ¸ë„¤ì„ìœ¼ë¡œ ë³€ê²½í•˜ì„¸ìš”.

ì‚¬ìš© ë°©ë²•
1) ë©”íŠ¸ë¦­ í™œì„±í™”(ì• í”Œë¦¬ì¼€ì´ì…˜):
```python
config.metrics.enabled = True
config.metrics.port = 9091
```

2) ìŠ¤íƒ ì‹¤í–‰:
```bash
docker compose up -d
```

3) í™•ì¸:
- Prometheus: http://localhost:9090 (target ìƒíƒœ í™•ì¸)
- Grafana: http://localhost:3000 (ê¸°ë³¸ admin / admin)

4) Grafana ë°ì´í„°ì†ŒìŠ¤ ì¶”ê°€:
- Type: Prometheus
- URL: http://prometheus:9090
- Access: Server

5) ëŒ€ì‹œë³´ë“œ:
- Kafka Exporter ê¸°ë³¸ ì§€í‘œ + Pyrallel Consumer `consumer_*` ë©”íŠ¸ë¦­ì„ ì„ íƒí•˜ì—¬ ê·¸ë˜í”„ íŒ¨ë„ì„ ì¶”ê°€í•˜ë©´ ë©ë‹ˆë‹¤.
- ì˜ˆì‹œ ì¿¼ë¦¬: `consumer_processed_total`, `consumer_processing_latency_seconds_bucket`, `consumer_in_flight_count`.

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

ëª¨ë“  ì»¤ë°‹ ë©”ì‹œì§€ëŠ” [Conventional Commits](https://www.conventionalcommits.org/ko/v1.0.0/) ìŠ¤í™ì„ ë”°ë¦…ë‹ˆë‹¤.

---
Â© 2026 Pyrallel Consumer Project
